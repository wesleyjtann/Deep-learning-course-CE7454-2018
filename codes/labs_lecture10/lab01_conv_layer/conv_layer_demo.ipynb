{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10.01 : Convolutional layer - demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a convolutional module\n",
    "* inputs:  2 channels\n",
    "* output:  5 activation maps \n",
    "* filters are 3x3\n",
    "* padding with one layer of zero to not shrink anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = nn.Conv2d( 2 , 5 ,  kernel_size=3,  padding=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make an input 2 x 6 x 6  (two channels, each one has 6 x 6 pixels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.1784, 0.3722, 0.3135, 0.8681, 0.5603, 0.2079],\n",
      "          [0.9363, 0.8443, 0.8515, 0.2553, 0.5105, 0.8482],\n",
      "          [0.1119, 0.7999, 0.9080, 0.2513, 0.6365, 0.7876],\n",
      "          [0.0709, 0.1471, 0.6620, 0.6763, 0.0782, 0.4592],\n",
      "          [0.0897, 0.0623, 0.9341, 0.7683, 0.7604, 0.8292],\n",
      "          [0.0084, 0.7799, 0.2410, 0.6735, 0.8646, 0.4548]],\n",
      "\n",
      "         [[0.4053, 0.4116, 0.5764, 0.2431, 0.8331, 0.6385],\n",
      "          [0.6246, 0.2053, 0.7000, 0.4831, 0.2516, 0.5654],\n",
      "          [0.2548, 0.8840, 0.6014, 0.0869, 0.1532, 0.2282],\n",
      "          [0.3570, 0.6875, 0.6426, 0.3577, 0.2863, 0.9814],\n",
      "          [0.5728, 0.9117, 0.4430, 0.7477, 0.3931, 0.3130],\n",
      "          [0.0549, 0.2686, 0.3305, 0.5118, 0.3321, 0.7649]]]])\n"
     ]
    }
   ],
   "source": [
    "bs=1\n",
    "\n",
    "x=torch.rand(bs,2,6,6)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed it to the convolutional layer: the output should have 5 channels (each one is 6x6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.1546,  0.1761,  0.3139,  0.3329,  0.2344,  0.2403],\n",
      "          [ 0.4526,  0.7836,  0.4721,  0.4402,  0.5568,  0.3465],\n",
      "          [ 0.4644,  0.5815,  0.8252,  0.5368,  0.5006,  0.6490],\n",
      "          [ 0.2608,  0.6508,  0.6952,  0.4918,  0.3423,  0.2017],\n",
      "          [ 0.0478,  0.3647,  0.6414,  0.6108,  0.5795,  0.6324],\n",
      "          [ 0.1970,  0.3411,  0.4235,  0.5146,  0.4885,  0.3434]],\n",
      "\n",
      "         [[-0.1756, -0.1892,  0.0342,  0.0636, -0.1037,  0.0879],\n",
      "          [-0.4237,  0.2110,  0.0016, -0.0115, -0.1457, -0.0481],\n",
      "          [-0.3072, -0.2332,  0.0658,  0.2021, -0.2678,  0.1540],\n",
      "          [-0.3314, -0.2749,  0.0221, -0.1188, -0.0806, -0.1863],\n",
      "          [-0.4099, -0.1695, -0.2206,  0.0867,  0.0872,  0.0715],\n",
      "          [-0.0680, -0.3594,  0.0421, -0.2217, -0.0682, -0.0914]],\n",
      "\n",
      "         [[-0.2504, -0.2301, -0.3474, -0.3336, -0.3999, -0.2530],\n",
      "          [-0.5108, -0.5159, -0.4399, -0.3622, -0.1104, -0.3336],\n",
      "          [-0.4865, -0.6728, -0.3808, -0.2202, -0.5820, -0.4804],\n",
      "          [-0.4265, -0.4185, -0.4142, -0.4817, -0.3215, -0.3148],\n",
      "          [-0.1560, -0.2235, -0.5468, -0.4916, -0.3123, -0.3666],\n",
      "          [ 0.0204, -0.3414, -0.5083, -0.3633, -0.5557, -0.4219]],\n",
      "\n",
      "         [[ 0.1182,  0.0860, -0.1304,  0.0357,  0.0497, -0.0819],\n",
      "          [-0.0401, -0.1711, -0.2162, -0.3637, -0.3769, -0.1386],\n",
      "          [-0.1362, -0.2875, -0.1408, -0.4126, -0.2334,  0.0727],\n",
      "          [-0.1204,  0.0843,  0.0741, -0.2498, -0.1995, -0.0878],\n",
      "          [ 0.0162, -0.3247, -0.1695, -0.2052, -0.5163,  0.0486],\n",
      "          [-0.2337, -0.2116, -0.4202, -0.5332, -0.5196, -0.2431]],\n",
      "\n",
      "         [[-0.2644, -0.2812, -0.4722, -0.1906, -0.1422, -0.3609],\n",
      "          [-0.3796, -0.2362, -0.5510, -0.4289, -0.3138, -0.2372],\n",
      "          [-0.2846, -0.4529, -0.3242, -0.3122, -0.4058, -0.1492],\n",
      "          [-0.4173, -0.6131, -0.2102, -0.3714, -0.3513, -0.4224],\n",
      "          [-0.2299, -0.6239, -0.3730, -0.2201, -0.4792, -0.3514],\n",
      "          [-0.3449, -0.3548, -0.1952, -0.3275, -0.0427, -0.0250]]]],\n",
      "       grad_fn=<ThnnConv2DBackward>)\n"
     ]
    }
   ],
   "source": [
    "y=mod(x)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets look at the 5 filters.\n",
    "* Our filters are 2x3x3\n",
    "* Each of the filter has 2 channels because the inputs have two channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.0233,  0.1426,  0.0316],\n",
       "          [ 0.1156,  0.1522,  0.1043],\n",
       "          [-0.0647, -0.0166,  0.0310]],\n",
       "\n",
       "         [[ 0.0001,  0.2227, -0.0002],\n",
       "          [ 0.1709, -0.1134, -0.0742],\n",
       "          [ 0.0146,  0.2104,  0.1196]]],\n",
       "\n",
       "\n",
       "        [[[-0.0525,  0.0200, -0.2195],\n",
       "          [ 0.2168,  0.0069,  0.1493],\n",
       "          [-0.1018,  0.0912, -0.1924]],\n",
       "\n",
       "         [[ 0.1100, -0.0833,  0.0666],\n",
       "          [ 0.1068, -0.1588,  0.0477],\n",
       "          [ 0.2040,  0.1601, -0.1015]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1061, -0.1744, -0.1497],\n",
       "          [-0.0760, -0.2121,  0.0178],\n",
       "          [ 0.0029,  0.0700,  0.0239]],\n",
       "\n",
       "         [[-0.1295,  0.1766,  0.0825],\n",
       "          [ 0.0341, -0.0964, -0.0001],\n",
       "          [ 0.1240, -0.1546, -0.1533]]],\n",
       "\n",
       "\n",
       "        [[[-0.2318,  0.0354, -0.2127],\n",
       "          [-0.1732, -0.0088, -0.1838],\n",
       "          [-0.0946, -0.0719,  0.1231]],\n",
       "\n",
       "         [[ 0.0793,  0.0701, -0.1581],\n",
       "          [-0.0736,  0.0013, -0.0161],\n",
       "          [ 0.2235,  0.1814,  0.0799]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0245,  0.0794, -0.2158],\n",
       "          [ 0.0975,  0.0674, -0.1066],\n",
       "          [-0.1876, -0.0634, -0.0119]],\n",
       "\n",
       "         [[ 0.1138, -0.1172, -0.1689],\n",
       "          [ 0.0208, -0.2253,  0.1656],\n",
       "          [-0.0178, -0.1451,  0.0654]]]], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
