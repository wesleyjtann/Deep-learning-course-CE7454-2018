{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10.01 : Convolutional layer - demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a convolutional module\n",
    "* inputs:  2 channels\n",
    "* output:  5 activation maps \n",
    "* filters are 3x3\n",
    "* padding with one layer of zero to not shrink anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = nn.Conv2d( 2 , 5 ,  kernel_size=3,  padding=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make an input 2 x 6 x 6  (two channels, each one has 6 x 6 pixels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.7047, 0.8313, 0.0759, 0.6920, 0.1386, 0.1157],\n",
      "          [0.7951, 0.4046, 0.4652, 0.4411, 0.4766, 0.3431],\n",
      "          [0.7591, 0.7909, 0.8014, 0.7906, 0.8385, 0.7155],\n",
      "          [0.0887, 0.5409, 0.1888, 0.3974, 0.0666, 0.4525],\n",
      "          [0.5457, 0.1318, 0.2658, 0.6402, 0.0804, 0.3179],\n",
      "          [0.6689, 0.8480, 0.5928, 0.5367, 0.0713, 0.8117]],\n",
      "\n",
      "         [[0.2297, 0.7990, 0.7770, 0.9968, 0.7932, 0.3846],\n",
      "          [0.0460, 0.7105, 0.0925, 0.3834, 0.8878, 0.1382],\n",
      "          [0.0827, 0.9483, 0.2697, 0.7253, 0.5145, 0.3794],\n",
      "          [0.1562, 0.9804, 0.1740, 0.0048, 0.1441, 0.1568],\n",
      "          [0.2589, 0.0965, 0.4725, 0.0589, 0.3132, 0.9981],\n",
      "          [0.8324, 0.2730, 0.1117, 0.0333, 0.4956, 0.6327]]]])\n"
     ]
    }
   ],
   "source": [
    "bs=1\n",
    "\n",
    "x=torch.rand(bs,2,6,6)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed it to the convolutional layer: the output should have 5 channels (each one is 6x6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0163, -0.3075, -0.3779, -0.3884, -0.5828, -0.3904],\n",
      "          [-0.0628, -0.4817, -0.2663, -0.2517, -0.3967, -0.3860],\n",
      "          [ 0.0193, -0.4532, -0.2394, -0.1139, -0.3157, -0.1572],\n",
      "          [ 0.0205, -0.4515, -0.2873, -0.2347, -0.3008, -0.2698],\n",
      "          [-0.1130, -0.4114, -0.1763, -0.2011, -0.2034, -0.4591],\n",
      "          [-0.1168, -0.0686, -0.1752,  0.0700,  0.1236, -0.2004]],\n",
      "\n",
      "         [[ 0.2804,  0.6240,  0.3630,  0.3204,  0.2628, -0.1202],\n",
      "          [ 0.6719,  0.7637,  0.4363,  0.8052,  0.3681, -0.0338],\n",
      "          [ 0.7203,  0.6237,  0.4467,  0.7014,  0.5152,  0.0786],\n",
      "          [ 0.6668,  0.5280,  0.4018,  0.2521,  0.5946,  0.0507],\n",
      "          [ 0.6005,  0.3151,  0.3248,  0.1489,  0.7286,  0.0719],\n",
      "          [ 0.4134,  0.2588,  0.4239,  0.3215,  0.6093,  0.0770]],\n",
      "\n",
      "         [[-0.0869, -0.3381, -0.1027, -0.1530, -0.1447,  0.0211],\n",
      "          [-0.4188, -0.6466, -0.5492, -0.8125, -0.5773, -0.3304],\n",
      "          [-0.3661, -0.4800, -0.4954, -0.4183, -0.3497, -0.3219],\n",
      "          [-0.2509, -0.3517, -0.3127, -0.3578, -0.4390, -0.3209],\n",
      "          [-0.2868, -0.4267, -0.2339, -0.2068, -0.1093, -0.2662],\n",
      "          [-0.1366, -0.0843, -0.1639, -0.2317, -0.0294, -0.1689]],\n",
      "\n",
      "         [[-0.5597, -0.3108, -0.4531, -0.6332, -0.0429,  0.0143],\n",
      "          [-0.7236, -0.6826, -0.8159, -1.0297, -0.7577, -0.1036],\n",
      "          [-0.8710, -0.3924, -0.4794, -0.6462, -0.6392, -0.0280],\n",
      "          [-0.5366, -0.7961, -0.3572, -0.3726, -0.7286, -0.0616],\n",
      "          [-0.2983, -0.4312, -0.5535, -0.2938, -0.5183, -0.0946],\n",
      "          [-0.5634, -0.2240, -0.0738, -0.2006, -0.6033, -0.4141]],\n",
      "\n",
      "         [[-0.0001, -0.0804, -0.3456,  0.0670, -0.1912, -0.2522],\n",
      "          [-0.1304, -0.2185, -0.3094, -0.1469, -0.2419, -0.2194],\n",
      "          [-0.2035, -0.3567, -0.6634, -0.6826, -0.3409, -0.3821],\n",
      "          [-0.3978, -0.2168, -0.4858, -0.2642, -0.2025, -0.0596],\n",
      "          [-0.1357, -0.1361, -0.2544, -0.0858,  0.0300, -0.2481],\n",
      "          [-0.4042, -0.5211, -0.4746, -0.3380, -0.5425, -0.1509]]]],\n",
      "       grad_fn=<ThnnConv2DBackward>)\n"
     ]
    }
   ],
   "source": [
    "y=mod(x)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets look at the 5 filters.\n",
    "* Our filters are 2x3x3\n",
    "* Each of the filter has 2 channels because the inputs have two channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.0457, -0.1455, -0.0871],\n",
       "          [-0.0836,  0.0778,  0.0118],\n",
       "          [-0.1273, -0.0603, -0.0130]],\n",
       "\n",
       "         [[ 0.1348, -0.0725,  0.1621],\n",
       "          [-0.1830, -0.1584,  0.1501],\n",
       "          [-0.0932, -0.1722, -0.1081]]],\n",
       "\n",
       "\n",
       "        [[[-0.1268,  0.0611,  0.2305],\n",
       "          [ 0.2105,  0.0632,  0.1279],\n",
       "          [ 0.1569, -0.1454,  0.1310]],\n",
       "\n",
       "         [[-0.0143,  0.0074,  0.2188],\n",
       "          [-0.2211,  0.1445,  0.1426],\n",
       "          [-0.1096,  0.1359,  0.0311]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1431, -0.2102, -0.0492],\n",
       "          [-0.1579, -0.2323, -0.0059],\n",
       "          [-0.1045, -0.0819,  0.0701]],\n",
       "\n",
       "         [[-0.2055, -0.1079, -0.1351],\n",
       "          [ 0.1137, -0.0497, -0.0226],\n",
       "          [-0.1469, -0.1901, -0.1081]]],\n",
       "\n",
       "\n",
       "        [[[-0.0339, -0.0906,  0.0820],\n",
       "          [ 0.2067, -0.0410, -0.2348],\n",
       "          [-0.1985,  0.0777, -0.1291]],\n",
       "\n",
       "         [[-0.1321, -0.2327, -0.2183],\n",
       "          [ 0.0391, -0.2292, -0.2249],\n",
       "          [ 0.0656,  0.1587, -0.2186]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1009, -0.0760, -0.1514],\n",
       "          [-0.2188, -0.0355, -0.2041],\n",
       "          [ 0.0714,  0.0546,  0.1783]],\n",
       "\n",
       "         [[-0.1160,  0.1043, -0.2216],\n",
       "          [-0.0168, -0.1375,  0.0944],\n",
       "          [-0.1715,  0.0787,  0.1330]]]], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
