{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 11: MLP -- exercise\n",
    "\n",
    "# Understanding the training loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from random import randint\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data and print the sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "train_data=torch.load('../data/fashion-mnist/train_data.pt')\n",
    "\n",
    "print(train_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "train_label=torch.load('../data/fashion-mnist/train_label.pt')\n",
    "\n",
    "print(train_label.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "test_data=torch.load('../data/fashion-mnist/test_data.pt')\n",
    "\n",
    "print(test_data.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a ONE layer net class. The network output are the scores! No softmax needed! You have only one line to write in the forward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class one_layer_net(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(one_layer_net , self).__init__()\n",
    "        self.linear_layer = # complete here\n",
    "        \n",
    "    def forward(self, x):\n",
    "        scores =  # complete here\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net= # complete here\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the criterion and the optimizer: use the CHEAT SHEET to see the correct syntax. \n",
    "\n",
    "### Remember that the optimizer need to have access to the parameters of the network (net.parameters()).\n",
    "\n",
    "### Set the batchize and learning rate to be:\n",
    "### batchize = 50\n",
    "### learning rate = 0.01\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the criterion\n",
    "criterion = # complete here\n",
    "\n",
    "# make the SGD optimizer. \n",
    "optimizer=torch.optim.SGD(  #complete here  )\n",
    "\n",
    "# set up the batch size   \n",
    "bs="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in range(1,5000):\n",
    "    \n",
    "    # Set dL/dU, dL/dV, dL/dW to be filled with zeros\n",
    "   \n",
    "     \n",
    "    # create a minibatch\n",
    "    \n",
    "    \n",
    "    \n",
    "    # reshape the minibatch\n",
    "\n",
    "    \n",
    "    # tell Pytorch to start tracking all operations that will be done on \"inputs\"\n",
    "\n",
    "\n",
    "    # forward the minibatch through the net  \n",
    "\n",
    "    \n",
    "    # Compute the average of the losses of the data points in the minibatch\n",
    "\n",
    "    \n",
    "    # backward pass to compute dL/dU, dL/dV and dL/dW    \n",
    "\n",
    "    \n",
    "    # do one step of stochastic gradient descent: U=U-lr(dL/dU), V=V-lr(dL/dU), ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose image at random from the test set and see how good/bad are the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a picture at random\n",
    "idx=randint(0, 10000-1)\n",
    "im=test_data[idx]\n",
    "\n",
    "# diplay the picture\n",
    "utils.show(im)\n",
    "\n",
    "# feed it to the net and display the confidence scores\n",
    "scores =  net( im.view(1,784)) \n",
    "probs= F.softmax(scores, dim=1)\n",
    "utils.show_prob_fashion_mnist(probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
